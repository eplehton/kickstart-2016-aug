---
title: "ANOVA"
author: "Esko"
date: "22.08.2016"
output: html_document
---


In the following, we will demonstrate how you would calculate one way or two-way ANOVAs in R. 

We will use the same data as in the _Testing for association between two continous variables_.


```{r}
game.wmc <- read.table("kr_gamewmc.txt", header=T)
game.wmc$accuracy <- game.wmc$Phit + game.wmc$PcorrectRejection
```

Then we will investigate accuracy as a function of age group and gender. 

Basically, because we are using a linear model, we can use function lm. 

```{r}

# single main effect models
fm.a <- lm(accuracy ~ age_grp, game.wmc)
fm.g <- lm(accuracy ~ gender, game.wmc)

# both main effects
fm.ag <- lm(accuracy ~ age_grp + gender, game.wmc)

# main effects and interaction
fm.ag <- lm(accuracy ~ age_grp * gender, game.wmc)

# age_grp * gender a shorthand for writing
fm.ag2 <- lm(accuracy ~ age_grp + gender + age_grp:gender, game.wmc)

```

We could use function anova to compare the models, and then select what to choose. But what if we would like to get the F-values for effects, in the exactly same way as in SPSS?

We could write 
```{r}
anova(fm.ag)
```

Unfortunately, this may not be what you wanted. Especially, the output is not the same as in SPSS by default.

R's anova calculates Type I Sum of Squares
--------------------------------------------------------

R's anova function give type I Sum of Squares, but SPSS tells us type III Sum of Squares by default. We can get type III Sum of Squares using function Anova from package car. I have deliberately decided not to show the example yet, because there is a high chance the output would be wrong, if you do not set the right contrasts. 


Why to use type III Sum of Squares?
---------------------------------------------------------------------

If the data were balanced, both type I and III Sum of Squares would produce exactly the same results. However, then number of children is larger than the number of males, the proportion of females in adult is group is not the same as in the children group, etc. 

```{r}
with(game.wmc, table(age_grp, gender))
```

_anova_ function uses type I Sum of Squares. When the data is unbalanced, the order in which the predictors are included into the model matters, because the are evaluated _sequentially_.  The first predictor explains all the variation it can, the second explains the portion of variance left over from the first predictor etc. 

In the case of an unbalanced design, this amounts to comparing group means weighted by their individual sample sizes, which is something that the researcher is not usually interested in. For a fine discussion of these issues, see the [presentation by Zhan](http://md.psych.bio.uni-goettingen.de/mv/unit/lm_cat/InteractionsAndTypesOfSS.pdf). 

In many cases, the resercher is interested in the unweighted means. That is, what is the effect after controlling for every other effect. In balanced designs, balancing ensures that we get the right results anyway, but with unbalanced design, we must use type III Sum of Squares to get the intended results. 

Consequently, the rule of thumb is to 'always' use type III Sum of Squares, because it would work also with balanced designs. 

With type III Sum of Squares, you must you orthogonal contrasts
------------------------------------------------------------------

You may remember from the statistical courses that if you use type III Sum of Squares, you must use orthogonal contrasts. Otherwise your results may be wrong. 

So what are orthogonal contrasts? First, analysis of variance can be tought as a linear model. When running a statistical test, the program estimates the parameters for each term in the model. Basically, constrasts define what does the parameter estimates in the fitted model mean. If the contrasts are not orthogonal, the procedure for calculating the type III Sum of Squares produces the wrong results. 

*The catch is that by default, the contrasts in R are not orthogonal.* 

You can check what are the current default contrasts. If you have not changed them, you will see that R uses treatment contrasts for unordered factors, and polynomous contrasts for ordered factors. The problem here is that treatment contrasts are not orthogonal. 

```{r eval=FALSE}
options("contrasts")

#$contrasts
#        unordered           ordered 
#"contr.treatment"      "contr.poly" 
```

You can set the default contrasts to be orthogonal like this.

```{r}
options(contrasts = c("contr.sum", "contr.poly"))

options("contrasts")
```

Below, there is an example of how the contrasts setting affects the results. 

```{r}
library(car) # load package car to get the function Anova

# This is right!
options(contrasts = c("contr.sum", "contr.poly"))
options("contrasts")

fm.ag <- lm(accuracy ~ age_grp * gender, game.wmc)
Anova(fm.ag, type=3)

# This is wrong! 
options(contrasts = c("contr.treatment", "contr.poly")) 
fm.ag <- lm(accuracy ~ age_grp * gender, game.wmc)
Anova(fm.ag, type=3)

# Set them back to orthogonal
options(contrasts = c("contr.sum", "contr.poly"))
options("contrasts")

```
You see that the for example the p-values produces are slightly different. 


Do not use type III Sum of Squares blindly
------------------------------------------------

The obvious question is why there are multiple types of Sum of Squares. Consider the following 
ANCOVA model, where we try to explain _accuracy_ by working memory capacity _pcu_score_ and _age_grp_.

It is not a surprice that adults have a higher working memory capacity than children.
```{r}
boxplot(pcu_score ~ age_grp, game.wmc)
```

_pcu_score_ predicts _accuracy_, as does _age_grp_.

```{r} 

fm.wmc <- lm(accuracy ~ pcu_score, game.wmc) 
summary(fm.wmc)
anova(fm.wmc) # ok to use type I Sum of Squares, because we have only one predictor

fm.age <- lm(accuracy ~ age_grp, game.wmc) 
summary(fm.age)
anova(fm.wmc)
```

But if we combine both, and use type III Sum of Squares, we get perplexing result
```{r}
options(contrasts = c("contr.sum", "contr.poly"))
fm.axw <- lm(accuracy ~ pcu_score + age_grp, game.wmc) 
summary(fm.axw)
Anova(fm.axw, type=3)
```
Anova tells us that neither of the effects is significant. This is because with type III, each effect is evaluated after controlling for all the others. Because pcu_score and age_grp are very strongly correlated, there is no variation left to be explained. 

In this case, you may not want to report the results of the previous F-test. Instead, you may want to either compare the two alternative models and say that they are not significantly different. Or, you can use type I Sum of Squares to investigate is there any age related variation left after controlling for the working memory capacity. 

```{r}
anova(fm.axw)
```

Note that we the data is still unbalanced, and therefore you are calculating unweighted means. 


